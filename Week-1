getwd()
setwd("E:/Ragha/Work")
getwd()

file.exists("data")
dir.create("data")
file.exists("data")             # Checks the File not Folder/Directory


if((!file.exists("data"))){     # Second Method
  dir.create("data")
}


# Downloading csv File 

fileUrl<- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"

download.file(fileUrl, destfile= "E:/Ragha/Work/data/camera.csv")

list.files("./data")

dateDownloaded<- date()
dateDownloaded
  

# Reading the file from CSV format

cameraData<- read.table("./data/camera.csv")
head(cameraData)

cameraData<- read.table("./data/camera.csv", sep= ",", header= TRUE)
head(cameraData)

cameraData<- read.csv("./data/camera.csv")
head(cameraData)

# Downloading xlsx File 

fileUrl<- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"

download.file(fileUrl, destfile= "E:/Ragha/Work/data/camera.xlsx", mode="wb")  # mode= "wb" download mode needs to be set properly as write-binary (wb) since xlsx is basically a binary file (zip)

list.files("./data")


# Reading the file from xlsx format

library(xlsx)
cameraData<- read.xlsx("./data/camera.xlsx", sheetIndex= 1, header= TRUE)
head(cameraData)


# Subsetting xlsx file

colIndex= 2:3
rowIndex= 1:4
cameraDataSubset<- read.xlsx("./data/camera.xlsx", sheetIndex= 1,  colIndex=colIndex, rowIndex=rowIndex)
head(cameraDataSubset)


# Downloading xml File 

fileUrl<- "http://www.w3schools.com/xml/note.xml"

download.file(fileUrl, destfile= "E:/Ragha/Work/data/camera.xml")

list.files("./data")

# Reading the file from xml format

library(XML)
library(RCurl)
doc<- xmlTreeParse(fileUrl, UseInternalNodes= TRUE) 
rootNode<- xmlRoot(doc)          # its like wrapper function and xmlroot is used to get the root elements
xmlName<- rootNode


# Downloading json File 

library(jsonlite)
jsonData<- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)





# datatable fast function, for subsetting grouping than dataframe

library(data.table)
DF<- data.frame(x= rnorm (9), y= rep(c("a", "b", "c"), each=3), z= rnorm(9))     # Dataframe
head(DF)
head(DF, 3)

DT<- data.table(x= rnorm (9), y= rep(c("a", "b", "c"), each=3), z= rnorm(9))     # Date table
head(DF, 3)

tables()                                                                         # info about table


# data table subsetting 

DT[2, ]
DT[DT$y== "a",  ]
DT[c(2, 3)]
DT[, c(2, 3)]


{
  x=1
  y=2
}
k= {print(10);5}
k

DT[, list(mean(x), sum(z))]
DT[, table(y)]
DT[, table(x)]

# Adding new coloumn using := , data table does not create a new copy unlike data frame so less memory

DT[, w:= z^2]
head(DT, 3)

# Careful 

DT2<- DT
DT[, y:=2]
head(DT, 3)
head(DT2, 3)                   # Though u copy it gets refleted in new variable so u can use copy() to solve this 

# Multiple operations (very important)

DT[, m:= {temp<- x+2; log2(temp+5)}]       # two Expressions, the one after ; is output, operates over each row
head(DT, 3)

# Plyr like operations

DT[, a:=x>0]
head(DT)
DT[, b:= mean(x+w), by=a]                  #by is Group by, Now mean of x+w place in all Trues and x+w and place in all False
head(DT)


# Special Variables

set.seed(123)
DT<- data.table(x= sample(letters[1:3], 1E5, TRUE))   # million times abc's 
head(DT)
DT[, .N]
DT[, .N, by=x]                             # Frequency of the groups appear


# Keys- Data tables have keys, makes easy to subset, sort rapidly than dframe

DT <- data.table(x=rep(c("a", "b", "c"), each=100), y=rnorm(300))
head(DT)
setkey(DT, x)                              # x is primary key
DT['a']                                    # Subsets only to value a

# Joins

DT1<- data.table(x=c("a", "a", "b", "dt1"), y =1:4)
DT2<- data.table(x=c("a", "b", "dt2"), y =5:7)
head(DT1); head(DT2)
head(DT1)
head(DT2)
setkey(DT1, x); setkey(DT2, x) 
merge(DT1, DT2)                             # inner join

# Fast reading- Proof

big_df<- data.frame(x=rnorm(1E6), y=rnorm(1E6))
file<- tempfile()

write.table(big_df, file=file, row.names= FALSE, col.names= TRUE, sep="\t", quote=FALSE )
system.time(fread(file))

system.time(read.table(file, header=TRUE, sep= "\t"))    # table takes lesser time


